{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG_WORD_TOKEN = \"<LONG_WORD>\"\n",
    "my_stop = set(stopwords.words('english')) # set of all stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    return pd.read_csv(\"train.csv\")\n",
    "\n",
    "def get_test_data():\n",
    "    test_comments = pd.read_csv(\"test.csv\")\n",
    "    test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "    return test_comments, test_labels\n",
    "\n",
    "def get_num_true_positives(predictions, truth):\n",
    "    \"\"\"\n",
    "    Return number of true positives in predictions\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: the number of times we predicted 1 and the truth was 1\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predictions) != len(truth):\n",
    "        print(\"get_num_true_positive: len(predictions) != len(truth)\")\n",
    "        return None\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 1 and truth[i] == 1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_num_false_positives(predictions, truth):\n",
    "    \"\"\"\n",
    "    Return number of false positives in predictions\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: the number of times we predicted 1 but the truth was 0\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predictions) != len(truth):\n",
    "        print(\"get_num_false_positive: len(predictions) != len(truth)\")\n",
    "        return None\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 1 and truth[i] == 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_num_false_negatives(predictions, truth):\n",
    "    \"\"\"\n",
    "    Return number of false negatives in predictions\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: the number of times we predicted 0 but the truth was 1\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predictions) != len(truth):\n",
    "        print(\"get_num_false_negatives: len(predictions) != len(truth)\")\n",
    "        return None\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 0 and truth[i] == 1:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def get_precision(predictions, truth):\n",
    "    \"\"\"\n",
    "    Calculates precision as defined by (true_positives) / (true_positives + false_positives)\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: precision\n",
    "    \"\"\"\n",
    "    \n",
    "    true_positives = get_num_true_positives(predictions, truth)\n",
    "    false_positives = get_num_false_positives(predictions, truth)\n",
    "    \n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def get_recall(predictions, truth):\n",
    "    \"\"\"\n",
    "    Calculates recall as defined by (true_positives) / (true_positives + false_negatives)\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: recall\n",
    "    \"\"\"\n",
    "    \n",
    "    true_positives = get_num_true_positives(predictions, truth)\n",
    "    false_negatives = get_num_false_negatives(predictions, truth)\n",
    "    \n",
    "    return true_positives / (true_positives + false_negatives)\n",
    "\n",
    "def f_beta_score(beta, predictions, truth):\n",
    "    precision = get_precision(predictions, truth)\n",
    "    recall = get_recall(predictions, truth)\n",
    "    numer = precision * recall\n",
    "    denom = ((beta**2) * precision) + recall\n",
    "    if denom == 0:\n",
    "        print(\"f_beta_score: denom == 0\")\n",
    "        return 0.0\n",
    "    factor = (1 + (beta**2))\n",
    "    \n",
    "    return factor * (numer / denom)\n",
    "\n",
    "def iter_ngram(n, words):\n",
    "    \"\"\"\n",
    "    Iterate over n-grams.\n",
    "\n",
    "    :param n: the \"n\"-gram\n",
    "    :param words: an iterable of words\n",
    "    :yield: the ngrams\n",
    "\n",
    "    >>> list(iter_ngram(1, ['hello', 'world']))\n",
    "    [('hello',), ('world',)]\n",
    "    >>> list(iter_ngram(2, ['hello', 'world']))\n",
    "    [('hello', 'world')]\n",
    "    \"\"\"\n",
    "    words = iter(words)\n",
    "    cache = collections.deque(maxlen=n)\n",
    "    try:\n",
    "        for _ in range(n - 1):\n",
    "            cache.append(next(words))\n",
    "    except StopIteration:\n",
    "        return\n",
    "    try:\n",
    "        for w in words:\n",
    "            cache.append(next(words))\n",
    "            yield tuple(cache)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "def count_ngram(n, ngrams_list):\n",
    "    \"\"\"\n",
    "    Count occurrences of\n",
    "    :param n: the \"n\"-gram\n",
    "    :param ngrams_list: list of ngrams\n",
    "    :return: a dict of ngram-to-count\n",
    "\n",
    "    >>> cnt = count_ngram(1, [[('hello',), ('world',)], [('again',)]])\n",
    "    \"\"\"\n",
    "    c = collections.Counter()\n",
    "    for words in corpus:\n",
    "        for ng in iter_ngram(n, words):\n",
    "            c[ng] += 1\n",
    "    c = dict(c)\n",
    "    return c\n",
    "\n",
    "def preprocess_comments(corpus):\n",
    "    \"\"\"\n",
    "    Remove capital letters, remove punctuations, split into words, stem the words.\n",
    "\n",
    "    :param corpus: an iterable of comments\n",
    "    :return: a iterable of processed comments\n",
    "    \"\"\"\n",
    "    puncset = set(string.punctuation)\n",
    "    stemmer = PorterStemmer()\n",
    "    comments = corpus\n",
    "    \n",
    "    comments = iter(''.join(c for c in x if c not in puncset) for x in comments)\n",
    "    comments = iter(x.lower() for x in comments)\n",
    "    comments = iter(re.sub(r'([a-z])([0-9])', r'\\1 \\2', x) for x in comments)\n",
    "    comments = iter(re.sub(r'([0-9])([a-z])', r'\\1 \\2', x) for x in comments)\n",
    "    comments = map(str.split, comments)\n",
    "    ret = []\n",
    "    for comment in comments:\n",
    "        stemmed = []\n",
    "        for word in comment:\n",
    "            try:\n",
    "                stemmed.append(stemmer.stem(word))\n",
    "            except RecursionError:\n",
    "                print(\"stemmer recursion issue\")\n",
    "                stemmed.append(LONG_WORD_TOKEN)\n",
    "        ret.append(' '.join(stemmed))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessor(raw_string):\n",
    "    \"\"\"\n",
    "    Replace uppercase with lowercase, long words with LONG_WORD_TOKEN, and (maybe) remove punctuation\n",
    "    \n",
    "    :param raw_string: a raw comment (string)\n",
    "    :return: a processed string\n",
    "    \"\"\"\n",
    "    \n",
    "    puncset = set(string.punctuation)\n",
    "    puncset.discard(\"!\")\n",
    "    puncset.discard(\"?\")\n",
    "    puncset.discard(\"#\")\n",
    "    goodpuncset = set([\"!\", \"?\"])\n",
    "    raw_string = ''.join(\" \" + c if c in goodpuncset else c for c in raw_string.lower() if c not in puncset)\n",
    "    #raw_string = ''.join(c for c in raw_string.lower() if c not in puncset)\n",
    "    words = raw_string.strip().split(' ')\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        if len(word) > 30:\n",
    "            words[i] = LONG_WORD_TOKEN\n",
    "    return ' '.join(words)\n",
    "\n",
    "def custom_tokenizer(raw_string):\n",
    "    \"\"\"\n",
    "    Split words into tokens, preserving the LONG_WORD_TOKEN\n",
    "\n",
    "    :param raw_string: one comment, post-processing\n",
    "    :return: a list of processed tokens from comment\n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    tokenized_string = raw_string\n",
    "    tokenized_string = re.sub(r'([a-z])([0-9])', r'\\1 \\2', tokenized_string)\n",
    "    tokenized_string = re.sub(r'([0-9])([a-z])', r'\\1 \\2', tokenized_string)\n",
    "    tokenized_string = tokenized_string.split(' ')\n",
    "    return [word if word == LONG_WORD_TOKEN else stemmer.stem(word) for word in tokenized_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = sklearn.utils.shuffle(get_train_data())\n",
    "split = len(training_data)//2\n",
    "validation_data = training_data[split:]\n",
    "training_data = training_data[:split]\n",
    "test_comments, test_labels = get_test_data()\n",
    "test_data = test_comments.set_index('id').join(other=test_labels.set_index('id'))\n",
    "test_data = test_data[test_data.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154220</th>\n",
       "      <td>aa5dba16e10beeaa</td>\n",
       "      <td>Thank you for experimenting with the page Guit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63835</th>\n",
       "      <td>aacc2f5b963c23e6</td>\n",
       "      <td>By editing back, Wikibots can easily look thro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106658</th>\n",
       "      <td>3a79f766187aea21</td>\n",
       "      <td>\"\\n\\n Re: \"\"Oblateness constant\"\" \\n\\nHaha, my...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83573</th>\n",
       "      <td>df9e423f27161982</td>\n",
       "      <td>Deolis \\n\\nI have no idea what I'm supposed to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>0ff1ed81db0f366a</td>\n",
       "      <td>REDIRECT Talk:Japanese gunboat Sumida (1906)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "154220  aa5dba16e10beeaa  Thank you for experimenting with the page Guit...   \n",
       "63835   aacc2f5b963c23e6  By editing back, Wikibots can easily look thro...   \n",
       "106658  3a79f766187aea21  \"\\n\\n Re: \"\"Oblateness constant\"\" \\n\\nHaha, my...   \n",
       "83573   df9e423f27161982  Deolis \\n\\nI have no idea what I'm supposed to...   \n",
       "5974    0ff1ed81db0f366a       REDIRECT Talk:Japanese gunboat Sumida (1906)   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "154220      0             0        0       0       0              0  \n",
       "63835       0             0        0       0       0              0  \n",
       "106658      0             0        0       0       0              0  \n",
       "83573       0             0        0       0       0              0  \n",
       "5974        0             0        0       0       0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_comment_text = training_data.comment_text.tolist()\n",
    "training_toxic_labels = training_data.toxic.tolist()\n",
    "training_severe_labels = training_data.severe_toxic.tolist()\n",
    "training_obscene_labels = training_data.obscene.tolist()\n",
    "training_threat_labels = training_data.threat.tolist()\n",
    "training_insult_labels = training_data.insult.tolist()\n",
    "training_hate_labels = training_data.identity_hate.tolist()\n",
    "training_labels = list(zip(training_toxic_labels, training_severe_labels, training_obscene_labels, training_threat_labels, training_insult_labels, training_hate_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_validation_comment_text = validation_data.comment_text.tolist()\n",
    "validation_toxic_labels = validation_data.toxic.tolist()\n",
    "validation_severe_labels = validation_data.severe_toxic.tolist()\n",
    "validation_obscene_labels = validation_data.obscene.tolist()\n",
    "validation_threat_labels = validation_data.threat.tolist()\n",
    "validation_insult_labels = validation_data.insult.tolist()\n",
    "validation_hate_labels = validation_data.identity_hate.tolist()\n",
    "validation_labels = list(zip(validation_toxic_labels, validation_severe_labels, validation_obscene_labels, validation_threat_labels, validation_insult_labels, validation_hate_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23008503189233592\n"
     ]
    }
   ],
   "source": [
    "# develop baseline\n",
    "\"\"\"\n",
    "predict all are not toxic\n",
    "\"\"\"\n",
    "baseline_truth = [1 if sum(training_label) > 0 else 0 for training_label in training_labels]\n",
    "baseline_predictions = [0] * len(baseline_truth)\n",
    "for i in range(len(baseline_predictions)):\n",
    "    baseline_predictions[i] = random.randint(0,1)\n",
    "\n",
    "print(sklearn.metrics.fbeta_score(y_true=baseline_truth, y_pred=baseline_predictions, beta=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop tf-idf model\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(preprocessor=custom_preprocessor, tokenizer=custom_tokenizer, ngram_range=(1,5), stop_words='english', norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_X = vectorizer.fit_transform(raw_documents=raw_training_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiments for each comment in X using the raw comment\n",
    "training_sentiments = [0] * training_X.shape[0]\n",
    "for i in range(len(training_sentiments)):\n",
    "    blob = TextBlob(raw_training_comment_text[i])\n",
    "    training_sentiments[i] = (blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_training_X = training_X.tolil()\n",
    "num_rows, num_cols = training_X.shape\n",
    "lil_training_X.resize((num_rows, num_cols + 1))\n",
    "for i in range(num_rows):\n",
    "    lil_training_X[i,-1] = training_sentiments[i][0]\n",
    "training_X = lil_training_X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y = [1 if sum(training_label) > 0 else 0 for training_label in training_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.Ridge(1.0)\n",
    "clf.fit(training_X, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = [0 if pred < 0.5 else 1 for pred in clf.predict(training_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9889488563351323"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.fbeta_score(y_true=training_y, y_pred=training_predictions, beta=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X = vectorizer.transform(raw_documents=raw_validation_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiments for each comment in X using the raw comment\n",
    "validation_sentiments = [0] * validation_X.shape[0]\n",
    "for i in range(len(validation_sentiments)):\n",
    "    blob = TextBlob(raw_validation_comment_text[i])\n",
    "    validation_sentiments[i] = (blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_validation_X = validation_X.tolil()\n",
    "num_rows, num_cols = validation_X.shape\n",
    "lil_validation_X.resize((num_rows, num_cols + 1))\n",
    "for i in range(num_rows):\n",
    "    lil_validation_X[i,-1] = validation_sentiments[i][0]\n",
    "validation_X = lil_validation_X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_y = [1 if sum(validation_label) > 0 else 0 for validation_label in validation_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = [0 if pred < 0.5 else 1 for pred in clf.predict(validation_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7301888687964637"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.fbeta_score(y_true=validation_y, y_pred=validation_predictions, beta=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'my', 'name', 'is', '<LONG_WORD>', 'mikey', '!', '#swag']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer(custom_preprocessor(\"Hello, my name is jaishriramanujanchanduranjanbalasubranium mikey! #swag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"hello, thsi is speled incorrectily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 1.0)]\n",
      "[('this', 1.0)]\n",
      "[('is', 1.0)]\n",
      "[('speed', 0.96875), ('spelled', 0.03125)]\n",
      "[('incorrectly', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "for word in blob.split():\n",
    "    w = textblob.blob.Word(word)\n",
    "    print(w.spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<textblob.decorators.cached_property at 0x1a749d2978>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.blob.TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
