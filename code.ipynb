{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "import itertools\n",
    "import sklearn\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG_WORD_TOKEN = \"<LONG_WORD>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    return pd.read_csv(\"train.csv\")\n",
    "\n",
    "def get_test_data():\n",
    "    test_comments = pd.read_csv(\"test.csv\")\n",
    "    test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "    return test_comments, test_labels\n",
    "\n",
    "def get_num_true_positives(predictions, truth):\n",
    "    \"\"\"\n",
    "    Return number of true positives in predictions\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: the number of times we predicted 1 and the truth was 1\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predictions) != len(truth):\n",
    "        print(\"get_num_true_positive: len(predictions) != len(truth)\")\n",
    "        return None\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 1 and truth[i] == 1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_num_false_positives(predictions, truth):\n",
    "    \"\"\"\n",
    "    Return number of false positives in predictions\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: the number of times we predicted 1 but the truth was 0\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predictions) != len(truth):\n",
    "        print(\"get_num_false_positive: len(predictions) != len(truth)\")\n",
    "        return None\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 1 and truth[i] == 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def get_num_false_negatives(predictions, truth):\n",
    "    \"\"\"\n",
    "    Return number of false negatives in predictions\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: the number of times we predicted 0 but the truth was 1\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(predictions) != len(truth):\n",
    "        print(\"get_num_false_negatives: len(predictions) != len(truth)\")\n",
    "        return None\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 0 and truth[i] == 1:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def get_precision(predictions, truth):\n",
    "    \"\"\"\n",
    "    Calculates precision as defined by (true_positives) / (true_positives + false_positives)\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: precision\n",
    "    \"\"\"\n",
    "    \n",
    "    true_positives = get_num_true_positives(predictions, truth)\n",
    "    false_positives = get_num_false_positives(predictions, truth)\n",
    "    \n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def get_recall(predictions, truth):\n",
    "    \"\"\"\n",
    "    Calculates recall as defined by (true_positives) / (true_positives + false_negatives)\n",
    "    \n",
    "    :param predictions: a vector of predicted classifications\n",
    "    :param truth: a vector of true classifications\n",
    "    :return: recall\n",
    "    \"\"\"\n",
    "    \n",
    "    true_positives = get_num_true_positives(predictions, truth)\n",
    "    false_negatives = get_num_false_negatives(predictions, truth)\n",
    "    \n",
    "    return true_positives / (true_positives + false_negatives)\n",
    "\n",
    "def f_beta_score(beta, predictions, truth):\n",
    "    precision = get_precision(predictions, truth)\n",
    "    recall = get_recall(predictions, truth)\n",
    "    numer = precision * recall\n",
    "    denom = ((beta**2) * precision) + recall\n",
    "    if denom == 0:\n",
    "        print(\"f_beta_score: denom == 0\")\n",
    "        return 0.0\n",
    "    factor = (1 + (beta**2))\n",
    "    \n",
    "    return factor * (numer / denom)\n",
    "\n",
    "def iter_ngram(n, words):\n",
    "    \"\"\"\n",
    "    Iterate over n-grams.\n",
    "\n",
    "    :param n: the \"n\"-gram\n",
    "    :param words: an iterable of words\n",
    "    :yield: the ngrams\n",
    "\n",
    "    >>> list(iter_ngram(1, ['hello', 'world']))\n",
    "    [('hello',), ('world',)]\n",
    "    >>> list(iter_ngram(2, ['hello', 'world']))\n",
    "    [('hello', 'world')]\n",
    "    \"\"\"\n",
    "    words = iter(words)\n",
    "    cache = collections.deque(maxlen=n)\n",
    "    try:\n",
    "        for _ in range(n - 1):\n",
    "            cache.append(next(words))\n",
    "    except StopIteration:\n",
    "        return\n",
    "    try:\n",
    "        for w in words:\n",
    "            cache.append(next(words))\n",
    "            yield tuple(cache)\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "def count_ngram(n, ngrams_list):\n",
    "    \"\"\"\n",
    "    Count occurrences of\n",
    "    :param n: the \"n\"-gram\n",
    "    :param ngrams_list: list of ngrams\n",
    "    :return: a dict of ngram-to-count\n",
    "\n",
    "    >>> cnt = count_ngram(1, [[('hello',), ('world',)], [('again',)]])\n",
    "    \"\"\"\n",
    "    c = collections.Counter()\n",
    "    for words in corpus:\n",
    "        for ng in iter_ngram(n, words):\n",
    "            c[ng] += 1\n",
    "    c = dict(c)\n",
    "    return c\n",
    "\n",
    "def preprocess_comments(corpus):\n",
    "    \"\"\"\n",
    "    Remove capital letters, remove punctuations, split into words, stem the words.\n",
    "\n",
    "    :param corpus: an iterable of comments\n",
    "    :return: a iterable of processed comments\n",
    "    \"\"\"\n",
    "    puncset = set(string.punctuation)\n",
    "    stemmer = PorterStemmer()\n",
    "    comments = corpus\n",
    "    \n",
    "    comments = iter(''.join(c for c in x if c not in puncset) for x in comments)\n",
    "    comments = iter(x.lower() for x in comments)\n",
    "    comments = iter(re.sub(r'([a-z])([0-9])', r'\\1 \\2', x) for x in comments)\n",
    "    comments = iter(re.sub(r'([0-9])([a-z])', r'\\1 \\2', x) for x in comments)\n",
    "    comments = map(str.split, comments)\n",
    "    ret = []\n",
    "    for comment in comments:\n",
    "        stemmed = []\n",
    "        for word in comment:\n",
    "            try:\n",
    "                stemmed.append(stemmer.stem(word))\n",
    "            except RecursionError:\n",
    "                print(\"stemmer recursion issue\")\n",
    "                stemmed.append(LONG_WORD_TOKEN)\n",
    "        ret.append(stemmed)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = sklearn.utils.shuffle(get_train_data())\n",
    "split = len(training_data)//2\n",
    "validation_data = training_data[split:]\n",
    "training_data = training_data[:split]\n",
    "test_comments, test_labels = get_test_data()\n",
    "test_data = test_comments.set_index('id').join(other=test_labels.set_index('id'))\n",
    "test_data = test_data[test_data.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121942</th>\n",
       "      <td>8c58128b985073bd</td>\n",
       "      <td>\"\\n\\n Melanie Phillips \\n\\nHi, thanks for your...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125091</th>\n",
       "      <td>9d1a1f673e54014c</td>\n",
       "      <td>February 2006 \\n\\nPlease do not add spamlinks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37777</th>\n",
       "      <td>64d7880b6987daa6</td>\n",
       "      <td>I'm accused of sockpuppetry, but the author is...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38419</th>\n",
       "      <td>6691db7d86256ed8</td>\n",
       "      <td>User:Indianacademy\\n\\n{{Quote box\\n | quote  =...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158088</th>\n",
       "      <td>e89c8db2c672aafb</td>\n",
       "      <td>User categorisation\\nYou were listed on the Wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "121942  8c58128b985073bd  \"\\n\\n Melanie Phillips \\n\\nHi, thanks for your...   \n",
       "125091  9d1a1f673e54014c  February 2006 \\n\\nPlease do not add spamlinks ...   \n",
       "37777   64d7880b6987daa6  I'm accused of sockpuppetry, but the author is...   \n",
       "38419   6691db7d86256ed8  User:Indianacademy\\n\\n{{Quote box\\n | quote  =...   \n",
       "158088  e89c8db2c672aafb  User categorisation\\nYou were listed on the Wi...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "121942      0             0        0       0       0              0  \n",
       "125091      0             0        0       0       0              0  \n",
       "37777       1             0        0       0       0              0  \n",
       "38419       0             0        0       0       0              0  \n",
       "158088      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_comment_text = training_data.comment_text.tolist()\n",
    "toxic_labels = training_data.toxic.tolist()\n",
    "severe_labels = training_data.severe_toxic.tolist()\n",
    "obscene_labels = training_data.obscene.tolist()\n",
    "threat_labels = training_data.threat.tolist()\n",
    "insult_labels = training_data.insult.tolist()\n",
    "hate_labels = training_data.identity_hate.tolist()\n",
    "labels = list(zip(toxic_labels, severe_labels, obscene_labels, threat_labels, insult_labels, hate_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 0, 0, 0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmer recursion issue\n"
     ]
    }
   ],
   "source": [
    "words = set()\n",
    "bag_of_comments = preprocess_comments(raw_comment_text)\n",
    "for comment in bag_of_comments:\n",
    "    for word in comment:\n",
    "        words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2274369476180211\n",
      "0.2274369476180211\n",
      "0.10172210663524929\n",
      "0.10172210663524929\n",
      "0.5046008455608058\n",
      "0.5046008455608058\n"
     ]
    }
   ],
   "source": [
    "# develop baseline\n",
    "\"\"\"\n",
    "predict all are not toxic\n",
    "\"\"\"\n",
    "truth = [1 if sum(label) > 0 else 0 for label in labels]\n",
    "predictions = [0] * len(truth)\n",
    "half = len(predictions)//2\n",
    "for i in range(half, len(predictions)):\n",
    "    predictions[i] = 1\n",
    "\n",
    "print(f_beta_score(beta=1.5, predictions=predictions, truth=truth))\n",
    "print(sklearn.metrics.fbeta_score(y_true=truth, y_pred=predictions, beta=1.5))\n",
    "\n",
    "print(get_precision(predictions=predictions, truth=truth))\n",
    "print(sklearn.metrics.precision_score(y_true=truth, y_pred=predictions))\n",
    "\n",
    "print(get_recall(predictions=predictions, truth=truth))\n",
    "print(sklearn.metrics.recall_score(y_true=truth, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop tf-idf model\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(raw_documents=raw_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_validation_comment_text = validation_data.comment_text.tolist()\n",
    "valid_X = vectorizer.transform(raw_documents=raw_validation_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=False, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = sklearn.linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predictions = [0 if pred < 0.5 else 1 for pred in clf.predict(valid_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6238348796267295\n"
     ]
    }
   ],
   "source": [
    "valid_labels = list(zip(validation_data.toxic.tolist(), validation_data.severe_toxic.tolist(), validation_data.obscene.tolist(), validation_data.threat.tolist(), validation_data.insult.tolist(), validation_data.identity_hate.tolist()))\n",
    "valid_truth = [1 if sum(label) > 0 else 0 for label in valid_labels]\n",
    "print(sklearn.metrics.fbeta_score(y_true=valid_truth, y_pred=valid_predictions, beta=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
