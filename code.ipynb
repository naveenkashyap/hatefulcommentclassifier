{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "import itertools\n",
    "import sklearn\n",
    "import pickle\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import sys\n",
    "import pdb\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename='launch.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG_WORD_TOKEN = \"<LONG_WORD>\"\n",
    "my_stop = set(stopwords.words('english')) # set of all stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    return pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    test_comments = pd.read_csv(\"test.csv\")\n",
    "    test_labels = pd.read_csv(\"test_labels.csv\")\n",
    "    return test_comments, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocessor(raw_string):\n",
    "    \"\"\"\n",
    "    Replace uppercase with lowercase, long words with LONG_WORD_TOKEN, and (maybe) remove punctuation\n",
    "    \n",
    "    :param raw_string: a raw comment (string)\n",
    "    :return: a processed string\n",
    "    \"\"\"\n",
    "    \n",
    "    puncset = set(string.punctuation)\n",
    "    puncset.discard(\"!\")\n",
    "    puncset.discard(\"?\")\n",
    "    puncset.discard(\"#\")\n",
    "    goodpuncset = set([\"!\", \"?\"])\n",
    "    raw_string = ''.join(\" \" + c if c in goodpuncset else c for c in raw_string.lower() if c not in puncset)\n",
    "    words = raw_string.strip().split()\n",
    "    for i in range(len(words)):\n",
    "        word = words[i]\n",
    "        if len(word) > 30:\n",
    "            words[i] = LONG_WORD_TOKEN\n",
    "    return ' '.join(words)\n",
    "\n",
    "def custom_tokenizer(raw_string):\n",
    "    \"\"\"\n",
    "    Split words into tokens, preserving the LONG_WORD_TOKEN\n",
    "\n",
    "    :param raw_string: one comment, post-processing\n",
    "    :return: a list of processed tokens from comment\n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    tokenized_string = raw_string\n",
    "    tokenized_string = re.sub(r'([a-z])([0-9])', r'\\1 \\2', tokenized_string)\n",
    "    tokenized_string = re.sub(r'([0-9])([a-z])', r'\\1 \\2', tokenized_string)\n",
    "    tokenized_string = list(\n",
    "        map(\n",
    "            lambda x: x[:15], \n",
    "            filter(\n",
    "                lambda x: not re.match(r'^\\d+$', x) and max(map(ord, x)) < 128, \n",
    "                tokenized_string.split()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return [word if word == LONG_WORD_TOKEN else stemmer.stem(word) for word in tokenized_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelspec2modelobj(cls, params):\n",
    "    args, kwargs = params\n",
    "    return cls(*args, **kwargs)\n",
    "\n",
    "\n",
    "def model_eval(X, y, model):\n",
    "    predictions = (model.predict(X) >= 0.5)\n",
    "    return sklearn.metrics.fbeta_score(y_true=y, y_pred=predictions, beta=1.5)\n",
    "\n",
    "\n",
    "def train_and_eval(X_train, y_train, X_valid, y_valid, model) -> float:\n",
    "    model.fit(X_train, y_train)\n",
    "    fbeta_train = model_eval(X_train, y_train, model)\n",
    "    fbeta_valid = model_eval(X_valid, y_valid, model)\n",
    "    logging.info('{} --- {}'.format(' '.join(\n",
    "        map(str.strip, str(model).split('\\n'))),\n",
    "        (fbeta_train, fbeta_valid)))\n",
    "    return fbeta_train, fbeta_valid\n",
    "\n",
    "def run_models(te, models):\n",
    "    \"\"\"\n",
    "    :param te: the ``train_and_eval`` function with the first four arguments\n",
    "           filled out\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        for ModelClass, all_params in tqdm(models.items(), ascii=True):\n",
    "            mobjs = map(partial(modelspec2modelobj, ModelClass), all_params)\n",
    "            fbs = pool.map(te, mobjs)\n",
    "            results[ModelClass.__name__] = list(zip(fbs, all_params))\n",
    "    return results\n",
    "\n",
    "\n",
    "models = {\n",
    "    sklearn.svm.SVC: [\n",
    "        ((2.0,), {'kernel': 'linear', 'gamma': 'auto', 'class_weight': 'balanced'})\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = sklearn.utils.shuffle(get_train_data())\n",
    "split = len(training_data)//2\n",
    "validation_data = training_data[split:]\n",
    "training_data = training_data[:split]\n",
    "test_comments, test_labels = get_test_data()\n",
    "test_data = test_comments.set_index('id').join(other=test_labels.set_index('id'))\n",
    "test_data = test_data[test_data.toxic != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76496</th>\n",
       "      <td>cccd00f521d911d5</td>\n",
       "      <td>Legal immunity NOT relevant to this page.  The...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20038</th>\n",
       "      <td>34f77901ec57e442</td>\n",
       "      <td>You currently appear to be engaged in an edit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52178</th>\n",
       "      <td>8b93c12382c926c5</td>\n",
       "      <td>\"::SV has recently gotten into an editing disp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26987</th>\n",
       "      <td>477875a62a6eab1d</td>\n",
       "      <td>It looks like I got confused. Your energy calc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130203</th>\n",
       "      <td>b894f7fcf621b189</td>\n",
       "      <td>Why is your user page the Green Day article? S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "76496   cccd00f521d911d5  Legal immunity NOT relevant to this page.  The...   \n",
       "20038   34f77901ec57e442  You currently appear to be engaged in an edit ...   \n",
       "52178   8b93c12382c926c5  \"::SV has recently gotten into an editing disp...   \n",
       "26987   477875a62a6eab1d  It looks like I got confused. Your energy calc...   \n",
       "130203  b894f7fcf621b189  Why is your user page the Green Day article? S...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "76496       0             0        0       0       0              0  \n",
       "20038       0             0        0       0       0              0  \n",
       "52178       0             0        0       0       0              0  \n",
       "26987       0             0        0       0       0              0  \n",
       "130203      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_training_comment_text = training_data.comment_text.tolist()\n",
    "training_toxic_labels = training_data.toxic.tolist()\n",
    "training_severe_labels = training_data.severe_toxic.tolist()\n",
    "training_obscene_labels = training_data.obscene.tolist()\n",
    "training_threat_labels = training_data.threat.tolist()\n",
    "training_insult_labels = training_data.insult.tolist()\n",
    "training_hate_labels = training_data.identity_hate.tolist()\n",
    "training_labels = np.array(list(zip(training_toxic_labels, training_severe_labels, training_obscene_labels, training_threat_labels, training_insult_labels, training_hate_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_validation_comment_text = validation_data.comment_text.tolist()\n",
    "validation_toxic_labels = validation_data.toxic.tolist()\n",
    "validation_severe_labels = validation_data.severe_toxic.tolist()\n",
    "validation_obscene_labels = validation_data.obscene.tolist()\n",
    "validation_threat_labels = validation_data.threat.tolist()\n",
    "validation_insult_labels = validation_data.insult.tolist()\n",
    "validation_hate_labels = validation_data.identity_hate.tolist()\n",
    "validation_labels = np.array(list(zip(validation_toxic_labels, validation_severe_labels, validation_obscene_labels, validation_threat_labels, validation_insult_labels, validation_hate_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22498253074802696\n"
     ]
    }
   ],
   "source": [
    "# develop baseline\n",
    "\"\"\"\n",
    "predict all are not toxic\n",
    "\"\"\"\n",
    "baseline_truth = [1 if sum(training_label) > 0 else 0 for training_label in training_labels]\n",
    "baseline_predictions = [0] * len(baseline_truth)\n",
    "for i in range(len(baseline_predictions)):\n",
    "    baseline_predictions[i] = random.randint(0,1)\n",
    "\n",
    "print(sklearn.metrics.fbeta_score(y_true=baseline_truth, y_pred=baseline_predictions, beta=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop tf-idf model\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(preprocessor=custom_preprocessor, tokenizer=custom_tokenizer, strip_accents='ascii', stop_words='english', norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "training_X = vectorizer.fit_transform(raw_documents=raw_training_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiments for each comment in X using the raw comment\n",
    "training_sentiments = [0] * training_X.shape[0]\n",
    "for i in range(len(training_sentiments)):\n",
    "    blob = TextBlob(raw_training_comment_text[i])\n",
    "    training_sentiments[i] = (blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_training_X = training_X.tolil()\n",
    "num_rows, num_cols = training_X.shape\n",
    "lil_training_X.resize((num_rows, num_cols + 1))\n",
    "for i in range(num_rows):\n",
    "    lil_training_X[i,-1] = training_sentiments[i][0]\n",
    "training_X = lil_training_X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y = [1 if sum(training_label) > 0 else 0 for training_label in training_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_X = vectorizer.transform(raw_documents=raw_validation_comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiments for each comment in X using the raw comment\n",
    "validation_sentiments = [0] * validation_X.shape[0]\n",
    "for i in range(len(validation_sentiments)):\n",
    "    blob = TextBlob(raw_validation_comment_text[i])\n",
    "    validation_sentiments[i] = (blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_validation_X = validation_X.tolil()\n",
    "num_rows, num_cols = validation_X.shape\n",
    "lil_validation_X.resize((num_rows, num_cols + 1))\n",
    "for i in range(num_rows):\n",
    "    lil_validation_X[i,-1] = validation_sentiments[i][0]\n",
    "validation_X = lil_validation_X.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_y = [1 if sum(validation_label) > 0 else 0 for validation_label in validation_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543802821.001256\n"
     ]
    }
   ],
   "source": [
    "print(time.time())\n",
    "clf = sklearn.svm.SVC(C=2,kernel='linear',gamma='auto', class_weight='balanced')\n",
    "clf.fit(training_X, training_y)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = sklearn.linear_model.Ridge(1.0)\n",
    "#clf.fit(training_X, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = [0 if pred < 0.5 else 1 for pred in clf.predict(training_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93389656353465"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.fbeta_score(y_true=training_y, y_pred=training_predictions, beta=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = [0 if pred < 0.5 else 1 for pred in clf.predict(validation_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7735140638920709"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.fbeta_score(y_true=validation_y, y_pred=validation_predictions, beta=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(preprocessor=custom_preprocessor, tokenizer=custom_tokenizer, ngram_range=(1,5), stop_words='english', norm='l2')\n",
    "#clf = sklearn.svm.SVC(C=2,kernel='linear',gamma='auto', class_weight='balanced')\n",
    "#0.7688090369071965\n",
    "\n",
    "#vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(preprocessor=custom_preprocessor, tokenizer=custom_tokenizer, strip_accents='ascii', stop_words='english', norm='l2')\n",
    "#clf = sklearn.svm.SVC(C=2,kernel='linear',gamma='auto', class_weight='balanced')\n",
    "#0.7735140638920709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'my', 'name', 'is', '<LONG_WORD>', 'mikey', '!', '#swag']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer(custom_preprocessor(\"Hello, my name is jaishriramanujanchanduranjanbalasubranium mikey! #swag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"hello, thsi is speled incorrectily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 1.0)]\n",
      "[('this', 1.0)]\n",
      "[('is', 1.0)]\n",
      "[('speed', 0.96875), ('spelled', 0.03125)]\n",
      "[('incorrectly', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "for word in blob.split():\n",
    "    w = textblob.blob.Word(word)\n",
    "    print(w.spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543783101.677035\n"
     ]
    }
   ],
   "source": [
    "sorted(\n",
    "    set(\n",
    "        map(\n",
    "            lambda x: x[:15], \n",
    "            filter(\n",
    "                lambda x: not re.match(r'^\\d+$', x) and max(map(ord, x)) < 128, \n",
    "                words_in_toxic_comments - words_in_nontoxic_comments\n",
    "            )\n",
    "        )\n",
    "    ), \n",
    "    key=lambda x: (len(x),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello,', 'thi', 'boyyyyyyyyyyyyy', 'is', 'me']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer(\"hello, this boyyyyyyyyyyyyyyyyyyyyy is me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001ea8717f6de06</th>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000247e83dcc1211</th>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002f87b16116a7f</th>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003e1cccfd5a40a</th>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00059ace3e3e9a53</th>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000663aff0fffc80</th>\n",
       "      <td>this other one from 1897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000689dd34e20979</th>\n",
       "      <td>== Reason for banning throwing == \\n\\n This ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000844b52dee5f3f</th>\n",
       "      <td>|blocked]] from editing Wikipedia.   |</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00091c35fa9d0465</th>\n",
       "      <td>== Arabs are committing genocide in Iraq, but ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000968ce11f5ee34</th>\n",
       "      <td>Please stop. If you continue to vandalize Wiki...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009734200a85047</th>\n",
       "      <td>== Energy  == \\n\\n I have edited the introduct...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000a02d807ae0254</th>\n",
       "      <td>@RedSlash, cut it short. If you have sources s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bafe2080bba82</th>\n",
       "      <td>. \\n\\n           Jews are not a race because y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bf0a9894b2807</th>\n",
       "      <td>:::If Ollie or others think that one list of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000c9b92318552d1</th>\n",
       "      <td>Professors to the Manhatten Project.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000cf60dbaed8c02</th>\n",
       "      <td>\" \\n\\n :Not sure whether this is notable enoug...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000d4f120d5a7303</th>\n",
       "      <td>일이삼사오육칠팔구하고십이요 에헤헤 으헤 으헤 으허허</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001068b809feee6b</th>\n",
       "      <td>\" \\n\\n ==balance== \\n This page has one senten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011cefc680993ba</th>\n",
       "      <td>REDIRECT Talk:Mi Vida Eres Tú</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011ef6aa33d42e6</th>\n",
       "      <td>\" \\n I'm not convinced that he was blind. Wher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012bb72f20ae971</th>\n",
       "      <td>\" \\n\\n == Ref: SS Ponzi Scheme == \\n\\n Hi Padi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00137446b1aec28c</th>\n",
       "      <td>== September 20th Truce == \\n\\n According to s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013a435effa29bd</th>\n",
       "      <td>I'd never think I'd need to say it, but Wikipe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013be435187e84f</th>\n",
       "      <td>But this is not the article about government p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013fed3aeae76b7</th>\n",
       "      <td>DJ Robinson is gay as hell! he sucks his dick ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001411adf8f1dd82</th>\n",
       "      <td>== Dracula's Grandmother == \\n\\n  \\n Dracula's...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001426f56de6a49b</th>\n",
       "      <td>*I agree with Billfruge. The author describes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0016b94c8b20ffa6</th>\n",
       "      <td>I WILL BURN YOU TO HELL IF YOU REVOKE MY TALK ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00177176f33f587e</th>\n",
       "      <td>== Can you work your magic? == \\n\\n Hi.  I was...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0017d4d47894af05</th>\n",
       "      <td>:Fuck off, you anti-semitic cunt.  |</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe05a286c1ccdf4</th>\n",
       "      <td>\" \\n\\n == Thanks == \\n\\n ...for this. I forgot...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe154eb8e9109c4</th>\n",
       "      <td>I would like to know when the facemask was fir...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe319146de940d2</th>\n",
       "      <td>The Yatt got me, this is insane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe3a3e2d8f0eb9b</th>\n",
       "      <td>This is my user talk page sandbox. I have the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe42bc39a1824b9</th>\n",
       "      <td>\" \\n\\n  \\n\\n  \\n\\n  \\n\\n  \\n\\n  \\n\\n {{pressmu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe556b78cec812e</th>\n",
       "      <td>africa gives aids and ebola \\n thank africa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe5685dbc45e616</th>\n",
       "      <td>\" \\n\\n == Eureka, California == \\n\\n Thank you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe6cd34eb78031a</th>\n",
       "      <td>::Also, note that the paragraph goes on to dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe860ce0e534ecc</th>\n",
       "      <td>\"::::::::P.S.: Ah, I now see you probably got ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe8c913b22202fc</th>\n",
       "      <td>\" \\n\\n You haven't shown why you regard the \"\"...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe8f452981b2f6e</th>\n",
       "      <td>==Suicide== \\n\\n Anyone know why he committed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffea5ae063edd2b4</th>\n",
       "      <td>\" \\n :I'm afraid that I have to share their co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffeaf5179971287c</th>\n",
       "      <td>\" \\n\\n == Homosexuality - Discrepency == \\n\\n ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffeb7faf9662ed0f</th>\n",
       "      <td>(UTC) \\n\\n ::FYI, I'm currently in edit confli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffebe90c8d5acaba</th>\n",
       "      <td>\" \\n\\n == IRAN == \\n That’s right, Iran. It wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff0547cf8a2abce</th>\n",
       "      <td>Thank you Gary, that does make me feel welcome...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff095881cc3eda7</th>\n",
       "      <td>\" ..... added at by  \\n\\n :Somebody using the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff23c3e174e895e</th>\n",
       "      <td>\" \\n 've been reading this talk page and I was...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff3ae2e177b6bb3</th>\n",
       "      <td>\" \\n\\n == Same coffee shop? == \\n\\n My memory ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff5c4a77fe0c05f</th>\n",
       "      <td>\"== Your edit to Maungaturoto == \\n Please don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff69311f306df44</th>\n",
       "      <td>Balancing the two approaches to psychiatry ( b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff7159b3ee95618</th>\n",
       "      <td>== Your name mentioned == \\n Hi, I just though...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff718ffe5f05559</th>\n",
       "      <td>I've just discovered yet another list: List of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff83b80284d8440</th>\n",
       "      <td>::Consensus for ruining Wikipedia? I think tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8f521a7dbcd47</th>\n",
       "      <td>shut down the mexican border withought looking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8f64043129fa2</th>\n",
       "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff9d70fe0722906</th>\n",
       "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffa8a11c4378854</th>\n",
       "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffac2a094c8e0e2</th>\n",
       "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffb5451268fb5ba</th>\n",
       "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63978 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0001ea8717f6de06  Thank you for understanding. I think very high...      0   \n",
       "000247e83dcc1211                   :Dear god this site is horrible.      0   \n",
       "0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...      0   \n",
       "0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...      0   \n",
       "00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...      0   \n",
       "000663aff0fffc80                           this other one from 1897      0   \n",
       "000689dd34e20979  == Reason for banning throwing == \\n\\n This ar...      0   \n",
       "000844b52dee5f3f             |blocked]] from editing Wikipedia.   |      0   \n",
       "00091c35fa9d0465  == Arabs are committing genocide in Iraq, but ...      1   \n",
       "000968ce11f5ee34  Please stop. If you continue to vandalize Wiki...      0   \n",
       "0009734200a85047  == Energy  == \\n\\n I have edited the introduct...      0   \n",
       "000a02d807ae0254  @RedSlash, cut it short. If you have sources s...      0   \n",
       "000bafe2080bba82  . \\n\\n           Jews are not a race because y...      0   \n",
       "000bf0a9894b2807  :::If Ollie or others think that one list of t...      0   \n",
       "000c9b92318552d1               Professors to the Manhatten Project.      0   \n",
       "000cf60dbaed8c02  \" \\n\\n :Not sure whether this is notable enoug...      0   \n",
       "000d4f120d5a7303                       일이삼사오육칠팔구하고십이요 에헤헤 으헤 으헤 으허허      0   \n",
       "001068b809feee6b  \" \\n\\n ==balance== \\n This page has one senten...      0   \n",
       "0011cefc680993ba                      REDIRECT Talk:Mi Vida Eres Tú      0   \n",
       "0011ef6aa33d42e6  \" \\n I'm not convinced that he was blind. Wher...      0   \n",
       "0012bb72f20ae971  \" \\n\\n == Ref: SS Ponzi Scheme == \\n\\n Hi Padi...      0   \n",
       "00137446b1aec28c  == September 20th Truce == \\n\\n According to s...      0   \n",
       "0013a435effa29bd  I'd never think I'd need to say it, but Wikipe...      0   \n",
       "0013be435187e84f  But this is not the article about government p...      0   \n",
       "0013fed3aeae76b7  DJ Robinson is gay as hell! he sucks his dick ...      1   \n",
       "001411adf8f1dd82  == Dracula's Grandmother == \\n\\n  \\n Dracula's...      0   \n",
       "001426f56de6a49b  *I agree with Billfruge. The author describes ...      0   \n",
       "0016b94c8b20ffa6  I WILL BURN YOU TO HELL IF YOU REVOKE MY TALK ...      0   \n",
       "00177176f33f587e  == Can you work your magic? == \\n\\n Hi.  I was...      0   \n",
       "0017d4d47894af05               :Fuck off, you anti-semitic cunt.  |      1   \n",
       "...                                                             ...    ...   \n",
       "ffe05a286c1ccdf4  \" \\n\\n == Thanks == \\n\\n ...for this. I forgot...      0   \n",
       "ffe154eb8e9109c4  I would like to know when the facemask was fir...      0   \n",
       "ffe319146de940d2                    The Yatt got me, this is insane      0   \n",
       "ffe3a3e2d8f0eb9b  This is my user talk page sandbox. I have the ...      0   \n",
       "ffe42bc39a1824b9  \" \\n\\n  \\n\\n  \\n\\n  \\n\\n  \\n\\n  \\n\\n {{pressmu...      0   \n",
       "ffe556b78cec812e        africa gives aids and ebola \\n thank africa      0   \n",
       "ffe5685dbc45e616  \" \\n\\n == Eureka, California == \\n\\n Thank you...      0   \n",
       "ffe6cd34eb78031a  ::Also, note that the paragraph goes on to dis...      0   \n",
       "ffe860ce0e534ecc  \"::::::::P.S.: Ah, I now see you probably got ...      0   \n",
       "ffe8c913b22202fc  \" \\n\\n You haven't shown why you regard the \"\"...      0   \n",
       "ffe8f452981b2f6e  ==Suicide== \\n\\n Anyone know why he committed ...      0   \n",
       "ffea5ae063edd2b4  \" \\n :I'm afraid that I have to share their co...      0   \n",
       "ffeaf5179971287c  \" \\n\\n == Homosexuality - Discrepency == \\n\\n ...      0   \n",
       "ffeb7faf9662ed0f  (UTC) \\n\\n ::FYI, I'm currently in edit confli...      0   \n",
       "ffebe90c8d5acaba  \" \\n\\n == IRAN == \\n That’s right, Iran. It wa...      1   \n",
       "fff0547cf8a2abce  Thank you Gary, that does make me feel welcome...      0   \n",
       "fff095881cc3eda7  \" ..... added at by  \\n\\n :Somebody using the ...      0   \n",
       "fff23c3e174e895e  \" \\n 've been reading this talk page and I was...      0   \n",
       "fff3ae2e177b6bb3  \" \\n\\n == Same coffee shop? == \\n\\n My memory ...      0   \n",
       "fff5c4a77fe0c05f  \"== Your edit to Maungaturoto == \\n Please don...      0   \n",
       "fff69311f306df44  Balancing the two approaches to psychiatry ( b...      0   \n",
       "fff7159b3ee95618  == Your name mentioned == \\n Hi, I just though...      0   \n",
       "fff718ffe5f05559  I've just discovered yet another list: List of...      0   \n",
       "fff83b80284d8440  ::Consensus for ruining Wikipedia? I think tha...      0   \n",
       "fff8f521a7dbcd47  shut down the mexican border withought looking...      0   \n",
       "fff8f64043129fa2  :Jerome, I see you never got around to this…! ...      0   \n",
       "fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...      0   \n",
       "fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...      0   \n",
       "fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...      1   \n",
       "fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0001ea8717f6de06             0        0       0       0              0  \n",
       "000247e83dcc1211             0        0       0       0              0  \n",
       "0002f87b16116a7f             0        0       0       0              0  \n",
       "0003e1cccfd5a40a             0        0       0       0              0  \n",
       "00059ace3e3e9a53             0        0       0       0              0  \n",
       "000663aff0fffc80             0        0       0       0              0  \n",
       "000689dd34e20979             0        0       0       0              0  \n",
       "000844b52dee5f3f             0        0       0       0              0  \n",
       "00091c35fa9d0465             0        0       0       0              0  \n",
       "000968ce11f5ee34             0        0       0       0              0  \n",
       "0009734200a85047             0        0       0       0              0  \n",
       "000a02d807ae0254             0        0       0       0              0  \n",
       "000bafe2080bba82             0        0       0       0              0  \n",
       "000bf0a9894b2807             0        0       0       0              0  \n",
       "000c9b92318552d1             0        0       0       0              0  \n",
       "000cf60dbaed8c02             0        0       0       0              0  \n",
       "000d4f120d5a7303             0        0       0       0              0  \n",
       "001068b809feee6b             0        0       0       0              0  \n",
       "0011cefc680993ba             0        0       0       0              0  \n",
       "0011ef6aa33d42e6             0        0       0       0              0  \n",
       "0012bb72f20ae971             0        0       0       0              0  \n",
       "00137446b1aec28c             0        0       0       0              0  \n",
       "0013a435effa29bd             0        0       0       0              0  \n",
       "0013be435187e84f             0        0       0       0              0  \n",
       "0013fed3aeae76b7             0        1       0       1              1  \n",
       "001411adf8f1dd82             0        0       0       0              0  \n",
       "001426f56de6a49b             0        0       0       0              0  \n",
       "0016b94c8b20ffa6             0        0       0       0              0  \n",
       "00177176f33f587e             0        0       0       0              0  \n",
       "0017d4d47894af05             0        1       0       1              0  \n",
       "...                        ...      ...     ...     ...            ...  \n",
       "ffe05a286c1ccdf4             0        0       0       0              0  \n",
       "ffe154eb8e9109c4             0        0       0       0              0  \n",
       "ffe319146de940d2             0        0       0       0              0  \n",
       "ffe3a3e2d8f0eb9b             0        0       0       0              0  \n",
       "ffe42bc39a1824b9             0        0       0       0              0  \n",
       "ffe556b78cec812e             0        0       0       0              0  \n",
       "ffe5685dbc45e616             0        0       0       0              0  \n",
       "ffe6cd34eb78031a             0        0       0       0              0  \n",
       "ffe860ce0e534ecc             0        0       0       0              0  \n",
       "ffe8c913b22202fc             0        0       0       0              0  \n",
       "ffe8f452981b2f6e             0        0       0       0              0  \n",
       "ffea5ae063edd2b4             0        0       0       0              0  \n",
       "ffeaf5179971287c             0        0       0       0              0  \n",
       "ffeb7faf9662ed0f             0        0       0       0              0  \n",
       "ffebe90c8d5acaba             0        1       0       0              0  \n",
       "fff0547cf8a2abce             0        0       0       0              0  \n",
       "fff095881cc3eda7             0        0       0       0              0  \n",
       "fff23c3e174e895e             0        0       0       0              0  \n",
       "fff3ae2e177b6bb3             0        0       0       0              0  \n",
       "fff5c4a77fe0c05f             0        0       0       0              0  \n",
       "fff69311f306df44             0        0       0       0              0  \n",
       "fff7159b3ee95618             0        0       0       0              0  \n",
       "fff718ffe5f05559             0        0       0       0              0  \n",
       "fff83b80284d8440             0        0       0       0              0  \n",
       "fff8f521a7dbcd47             0        0       0       0              0  \n",
       "fff8f64043129fa2             0        0       0       0              0  \n",
       "fff9d70fe0722906             0        0       0       0              0  \n",
       "fffa8a11c4378854             0        0       0       0              0  \n",
       "fffac2a094c8e0e2             0        1       0       1              0  \n",
       "fffb5451268fb5ba             0        0       0       0              0  \n",
       "\n",
       "[63978 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
